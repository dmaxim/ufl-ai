{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nonlinear_overfitting.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dmaxim/ufl-ai/blob/main/nonlinear_overfitting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gKIuu-j7xTQ-"
      },
      "source": [
        "# introduction to model over-fitting\n",
        "\n",
        "You can find a supplemental video about this exercise [here](https://youtu.be/ogesATk-Jpw)\n",
        "\n",
        "Once you know how to systematically increase the depth and width of your neural network, you can very easily build *very* large networks with only a few lines of actual code.\n",
        "\n",
        "For example, the next code cell creates a neural network with over 33 *million* trainable parameters, in just a few seconds!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gEiAUsO7xSm4",
        "outputId": "eae821bf-bb2d-4fbf-8827-f24c3314b5cb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "nw_width = 512\n",
        "nw_hdpth = 128\n",
        "\n",
        "model = tf.keras.Sequential()\n",
        "model.add(tf.keras.layers.Dense(units=nw_width, activation=tf.keras.activations.relu, input_shape=[1]))\n",
        "for i in range(nw_hdpth):\n",
        "  model.add(tf.keras.layers.Dense(units=nw_width, activation=tf.keras.activations.relu))\n",
        "model.add(tf.keras.layers.Dense(units=1))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 512)               1024      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 512)               262656    \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 512)               262656    \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 512)               262656    \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 512)               262656    \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 512)               262656    \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 512)               262656    \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 512)               262656    \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 512)               262656    \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 512)               262656    \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 512)               262656    \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 512)               262656    \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 512)               262656    \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 512)               262656    \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 512)               262656    \n",
            "                                                                 \n",
            " dense_15 (Dense)            (None, 512)               262656    \n",
            "                                                                 \n",
            " dense_16 (Dense)            (None, 512)               262656    \n",
            "                                                                 \n",
            " dense_17 (Dense)            (None, 512)               262656    \n",
            "                                                                 \n",
            " dense_18 (Dense)            (None, 512)               262656    \n",
            "                                                                 \n",
            " dense_19 (Dense)            (None, 512)               262656    \n",
            "                                                                 \n",
            " dense_20 (Dense)            (None, 512)               262656    \n",
            "                                                                 \n",
            " dense_21 (Dense)            (None, 512)               262656    \n",
            "                                                                 \n",
            " dense_22 (Dense)            (None, 512)               262656    \n",
            "                                                                 \n",
            " dense_23 (Dense)            (None, 512)               262656    \n",
            "                                                                 \n",
            " dense_24 (Dense)            (None, 512)               262656    \n",
            "                                                                 \n",
            " dense_25 (Dense)            (None, 512)               262656    \n",
            "                                                                 \n",
            " dense_26 (Dense)            (None, 512)               262656    \n",
            "                                                                 \n",
            " dense_27 (Dense)            (None, 512)               262656    \n",
            "                                                                 \n",
            " dense_28 (Dense)            (None, 512)               262656    \n",
            "                                                                 \n",
            " dense_29 (Dense)            (None, 512)               262656    \n",
            "                                                                 \n",
            " dense_30 (Dense)            (None, 512)               262656    \n",
            "                                                                 \n",
            " dense_31 (Dense)            (None, 512)               262656    \n",
            "                                                                 \n",
            " dense_32 (Dense)            (None, 512)               262656    \n",
            "                                                                 \n",
            " dense_33 (Dense)            (None, 512)               262656    \n",
            "                                                                 \n",
            " dense_34 (Dense)            (None, 512)               262656    \n",
            "                                                                 \n",
            " dense_35 (Dense)            (None, 512)               262656    \n",
            "                                                                 \n",
            " dense_36 (Dense)            (None, 512)               262656    \n",
            "                                                                 \n",
            " dense_37 (Dense)            (None, 512)               262656    \n",
            "                                                                 \n",
            " dense_38 (Dense)            (None, 512)               262656    \n",
            "                                                                 \n",
            " dense_39 (Dense)            (None, 512)               262656    \n",
            "                                                                 \n",
            " dense_40 (Dense)            (None, 512)               262656    \n",
            "                                                                 \n",
            " dense_41 (Dense)            (None, 512)               262656    \n",
            "                                                                 \n",
            " dense_42 (Dense)            (None, 512)               262656    \n",
            "                                                                 \n",
            " dense_43 (Dense)            (None, 512)               262656    \n",
            "                                                                 \n",
            " dense_44 (Dense)            (None, 512)               262656    \n",
            "                                                                 \n",
            " dense_45 (Dense)            (None, 512)               262656    \n",
            "                                                                 \n",
            " dense_46 (Dense)            (None, 512)               262656    \n",
            "                                                                 \n",
            " dense_47 (Dense)            (None, 512)               262656    \n",
            "                                                                 \n",
            " dense_48 (Dense)            (None, 512)               262656    \n",
            "                                                                 \n",
            " dense_49 (Dense)            (None, 512)               262656    \n",
            "                                                                 \n",
            " dense_50 (Dense)            (None, 512)               262656    \n",
            "                                                                 \n",
            " dense_51 (Dense)            (None, 512)               262656    \n",
            "                                                                 \n",
            " dense_52 (Dense)            (None, 512)               262656    \n",
            "                                                                 \n",
            " dense_53 (Dense)            (None, 512)               262656    \n",
            "                                                                 \n",
            " dense_54 (Dense)            (None, 512)               262656    \n",
            "                                                                 \n",
            " dense_55 (Dense)            (None, 512)               262656    \n",
            "                                                                 \n",
            " dense_56 (Dense)            (None, 512)               262656    \n",
            "                                                                 \n",
            " dense_57 (Dense)            (None, 512)               262656    \n",
            "                                                                 \n",
            " dense_58 (Dense)            (None, 512)               262656    \n",
            "                                                                 \n",
            " dense_59 (Dense)            (None, 512)               262656    \n",
            "                                                                 \n",
            " dense_60 (Dense)            (None, 512)               262656    \n",
            "                                                                 \n",
            " dense_61 (Dense)            (None, 512)               262656    \n",
            "                                                                 \n",
            " dense_62 (Dense)            (None, 512)               262656    \n",
            "                                                                 \n",
            " dense_63 (Dense)            (None, 512)               262656    \n",
            "                                                                 \n",
            " dense_64 (Dense)            (None, 512)               262656    \n",
            "                                                                 \n",
            " dense_65 (Dense)            (None, 512)               262656    \n",
            "                                                                 \n",
            " dense_66 (Dense)            (None, 512)               262656    \n",
            "                                                                 \n",
            " dense_67 (Dense)            (None, 512)               262656    \n",
            "                                                                 \n",
            " dense_68 (Dense)            (None, 512)               262656    \n",
            "                                                                 \n",
            " dense_69 (Dense)            (None, 512)               262656    \n",
            "                                                                 \n",
            " dense_70 (Dense)            (None, 512)               262656    \n",
            "                                                                 \n",
            " dense_71 (Dense)            (None, 512)               262656    \n",
            "                                                                 \n",
            " dense_72 (Dense)            (None, 512)               262656    \n",
            "                                                                 \n",
            " dense_73 (Dense)            (None, 512)               262656    \n",
            "                                                                 \n",
            " dense_74 (Dense)            (None, 512)               262656    \n",
            "                                                                 \n",
            " dense_75 (Dense)            (None, 512)               262656    \n",
            "                                                                 \n",
            " dense_76 (Dense)            (None, 512)               262656    \n",
            "                                                                 \n",
            " dense_77 (Dense)            (None, 512)               262656    \n",
            "                                                                 \n",
            " dense_78 (Dense)            (None, 512)               262656    \n",
            "                                                                 \n",
            " dense_79 (Dense)            (None, 512)               262656    \n",
            "                                                                 \n",
            " dense_80 (Dense)            (None, 512)               262656    \n",
            "                                                                 \n",
            " dense_81 (Dense)            (None, 512)               262656    \n",
            "                                                                 \n",
            " dense_82 (Dense)            (None, 512)               262656    \n",
            "                                                                 \n",
            " dense_83 (Dense)            (None, 512)               262656    \n",
            "                                                                 \n",
            " dense_84 (Dense)            (None, 512)               262656    \n",
            "                                                                 \n",
            " dense_85 (Dense)            (None, 512)               262656    \n",
            "                                                                 \n",
            " dense_86 (Dense)            (None, 512)               262656    \n",
            "                                                                 \n",
            " dense_87 (Dense)            (None, 512)               262656    \n",
            "                                                                 \n",
            " dense_88 (Dense)            (None, 512)               262656    \n",
            "                                                                 \n",
            " dense_89 (Dense)            (None, 512)               262656    \n",
            "                                                                 \n",
            " dense_90 (Dense)            (None, 512)               262656    \n",
            "                                                                 \n",
            " dense_91 (Dense)            (None, 512)               262656    \n",
            "                                                                 \n",
            " dense_92 (Dense)            (None, 512)               262656    \n",
            "                                                                 \n",
            " dense_93 (Dense)            (None, 512)               262656    \n",
            "                                                                 \n",
            " dense_94 (Dense)            (None, 512)               262656    \n",
            "                                                                 \n",
            " dense_95 (Dense)            (None, 512)               262656    \n",
            "                                                                 \n",
            " dense_96 (Dense)            (None, 512)               262656    \n",
            "                                                                 \n",
            " dense_97 (Dense)            (None, 512)               262656    \n",
            "                                                                 \n",
            " dense_98 (Dense)            (None, 512)               262656    \n",
            "                                                                 \n",
            " dense_99 (Dense)            (None, 512)               262656    \n",
            "                                                                 \n",
            " dense_100 (Dense)           (None, 512)               262656    \n",
            "                                                                 \n",
            " dense_101 (Dense)           (None, 512)               262656    \n",
            "                                                                 \n",
            " dense_102 (Dense)           (None, 512)               262656    \n",
            "                                                                 \n",
            " dense_103 (Dense)           (None, 512)               262656    \n",
            "                                                                 \n",
            " dense_104 (Dense)           (None, 512)               262656    \n",
            "                                                                 \n",
            " dense_105 (Dense)           (None, 512)               262656    \n",
            "                                                                 \n",
            " dense_106 (Dense)           (None, 512)               262656    \n",
            "                                                                 \n",
            " dense_107 (Dense)           (None, 512)               262656    \n",
            "                                                                 \n",
            " dense_108 (Dense)           (None, 512)               262656    \n",
            "                                                                 \n",
            " dense_109 (Dense)           (None, 512)               262656    \n",
            "                                                                 \n",
            " dense_110 (Dense)           (None, 512)               262656    \n",
            "                                                                 \n",
            " dense_111 (Dense)           (None, 512)               262656    \n",
            "                                                                 \n",
            " dense_112 (Dense)           (None, 512)               262656    \n",
            "                                                                 \n",
            " dense_113 (Dense)           (None, 512)               262656    \n",
            "                                                                 \n",
            " dense_114 (Dense)           (None, 512)               262656    \n",
            "                                                                 \n",
            " dense_115 (Dense)           (None, 512)               262656    \n",
            "                                                                 \n",
            " dense_116 (Dense)           (None, 512)               262656    \n",
            "                                                                 \n",
            " dense_117 (Dense)           (None, 512)               262656    \n",
            "                                                                 \n",
            " dense_118 (Dense)           (None, 512)               262656    \n",
            "                                                                 \n",
            " dense_119 (Dense)           (None, 512)               262656    \n",
            "                                                                 \n",
            " dense_120 (Dense)           (None, 512)               262656    \n",
            "                                                                 \n",
            " dense_121 (Dense)           (None, 512)               262656    \n",
            "                                                                 \n",
            " dense_122 (Dense)           (None, 512)               262656    \n",
            "                                                                 \n",
            " dense_123 (Dense)           (None, 512)               262656    \n",
            "                                                                 \n",
            " dense_124 (Dense)           (None, 512)               262656    \n",
            "                                                                 \n",
            " dense_125 (Dense)           (None, 512)               262656    \n",
            "                                                                 \n",
            " dense_126 (Dense)           (None, 512)               262656    \n",
            "                                                                 \n",
            " dense_127 (Dense)           (None, 512)               262656    \n",
            "                                                                 \n",
            " dense_128 (Dense)           (None, 512)               262656    \n",
            "                                                                 \n",
            " dense_129 (Dense)           (None, 1)                 513       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 33,621,505\n",
            "Trainable params: 33,621,505\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XoWF6jSq0jcF"
      },
      "source": [
        "Given that it is *so* easy to build *very large* neural networks, you might be wondering why we don't just analyze *all data* with *very large* neural networks!\n",
        "\n",
        "Well, if you look at the neural-network literature, it may seem like we actually *do* analyze *all* data with *very large* neural networks. The 'size' (measured in number of trainable parameters) of state-of-the-art neural networks has been increasing *dramatically* over recent years, and it seems that - in many complex problem domains - larger networks often result in *better* inferences.\n",
        "\n",
        "There are some *technical* problems with naive implementations of *very deep* nerual networks - like the [vanishing gradient](https://en.wikipedia.org/wiki/Vanishing_gradient_problem) problem - but these problems have largely been solved by 'fancy' network architectures like [residual networks](https://en.wikipedia.org/wiki/Residual_neural_network).\n",
        "\n",
        "Of course, large networks must perform a *large number* of calculations, and calculations take time. Fortunately, the 'forward pass' through a neural network is *very fast*, even for large networks. Backpropagation during training can take a bit longer, but hardware acceleration using GPUs or other 'specialized' hardware has essentially solved this problem. I could probably train a 50-million-parameter network on my laptop (which has an NVIDIA GPU) in a few days, and a big computer with multiple GPUs could probably train it in under 5 minutes!\n",
        "\n",
        "Big networks also consume more memory, which could limit their use on 'small' devices like 'phones' and appliances (did you know both apple and android phones have dedicated hardware devoted to running neural networks?). However, cloud-based computing allows you to make predictions 'online', using any hardware available on the cloud; only the data and results need to be sent over the network.\n",
        "\n",
        "Simple optimization routines like stochastic gradient descent *can* get 'stuck' when used to train large networks, failing to find a good approximation of the loss function's *global optimum*. But there are *lots* of 'fancier' optimization methods that don't suffer as much from these problems.\n",
        "\n",
        "So, from a *computational* perspective, there doesn't seem to be any *strong* argument in favor of using *simpler* neural networks, at least not in general."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltfdlZKL8o6s"
      },
      "source": [
        "## a 'statistical' argument against very large neural networks\n",
        "\n",
        "Given enough time and computational resources, we could probably fit *any* arbitrarily complex neural network to *any* data set. But is it a 'good idea' to build 'arbitrarily complex' statistical models?\n",
        "\n",
        "Later on in the course, we'll spend a lot of time looking at \"overfitting\" with complex neural networks.\n",
        "\n",
        "In this notebook, I'd like to go through a short exercise that might get you thinking about some of the problems that could arise when the model becomes 'too complex' for the data.\n",
        "\n",
        "It will also give you a chance to practice building nonlinear neural networks!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EnjUhLRe942n"
      },
      "source": [
        "## back to 'linear' data\n",
        "\n",
        "To illustrate \"overfitting\", let's go back to considering some *simple* data simulated according to a linear model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_2diAjSx-EHN",
        "outputId": "59758464-0d94-4e52-bae6-ddb5dab9cbb1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        }
      },
      "source": [
        "import sklearn.datasets\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "x,y = sklearn.datasets.make_regression(n_samples=50,\n",
        "                                       n_features=1,\n",
        "                                       bias=0.0,\n",
        "                                       noise=30.0,\n",
        "                                       random_state=602951)\n",
        "y = y / 100.0\n",
        "\n",
        "plt.scatter(x,y, marker='o')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7af981a1a350>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kht8RoYP-Egj"
      },
      "source": [
        "This should look pretty familiar by now. We just simulated 50 1-dimensional data points along a diagonal line. We scaled the y-values, so they fall roughly between -1.5 and +1.5, but that's just for convenience."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mDD8euYu_LEk"
      },
      "source": [
        "Of course, we can fit a simple linear model to these data, and check the fit. This should also look fairly familar by now."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oaAHt5BX_TZC",
        "outputId": "ef68ac5d-70f4-4a3c-845f-fed3e5afd141",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "model = tf.keras.Sequential()\n",
        "model.add(tf.keras.layers.Dense(units=1, input_shape=[1]))\n",
        "model.compile(optimizer=tf.keras.optimizers.SGD(),\n",
        "              loss=tf.keras.losses.MeanSquaredError())\n",
        "model.summary()\n",
        "\n",
        "data = tf.data.Dataset.from_tensor_slices((x,y)).batch(10)\n",
        "model.fit(data, epochs=100)\n",
        "\n",
        "y_hat = model.predict(x)\n",
        "\n",
        "plt.scatter(x,y, marker='o')\n",
        "plt.scatter(x,y_hat, marker='+')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_130 (Dense)           (None, 1)                 2         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2\n",
            "Trainable params: 2\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0926\n",
            "Epoch 2/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0920\n",
            "Epoch 3/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0916\n",
            "Epoch 4/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0912\n",
            "Epoch 5/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0909\n",
            "Epoch 6/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0906\n",
            "Epoch 7/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0904\n",
            "Epoch 8/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0903\n",
            "Epoch 9/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0901\n",
            "Epoch 10/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0900\n",
            "Epoch 11/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0899\n",
            "Epoch 12/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0898\n",
            "Epoch 13/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0897\n",
            "Epoch 14/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0897\n",
            "Epoch 15/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0896\n",
            "Epoch 16/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0896\n",
            "Epoch 17/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0895\n",
            "Epoch 18/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0895\n",
            "Epoch 19/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0895\n",
            "Epoch 20/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0894\n",
            "Epoch 21/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0894\n",
            "Epoch 22/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0894\n",
            "Epoch 23/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0894\n",
            "Epoch 24/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0894\n",
            "Epoch 25/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0894\n",
            "Epoch 26/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0894\n",
            "Epoch 27/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0894\n",
            "Epoch 28/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0894\n",
            "Epoch 29/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0894\n",
            "Epoch 30/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0894\n",
            "Epoch 31/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0893\n",
            "Epoch 32/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0893\n",
            "Epoch 33/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0893\n",
            "Epoch 34/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0893\n",
            "Epoch 35/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0893\n",
            "Epoch 36/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0893\n",
            "Epoch 37/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0893\n",
            "Epoch 38/100\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0893\n",
            "Epoch 39/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0893\n",
            "Epoch 40/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0893\n",
            "Epoch 41/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0893\n",
            "Epoch 42/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0893\n",
            "Epoch 43/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0893\n",
            "Epoch 44/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0893\n",
            "Epoch 45/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0893\n",
            "Epoch 46/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0893\n",
            "Epoch 47/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0893\n",
            "Epoch 48/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0893\n",
            "Epoch 49/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0893\n",
            "Epoch 50/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0893\n",
            "Epoch 51/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0893\n",
            "Epoch 52/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0893\n",
            "Epoch 53/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0893\n",
            "Epoch 54/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0893\n",
            "Epoch 55/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0893\n",
            "Epoch 56/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0893\n",
            "Epoch 57/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0893\n",
            "Epoch 58/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0893\n",
            "Epoch 59/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0893\n",
            "Epoch 60/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0893\n",
            "Epoch 61/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0893\n",
            "Epoch 62/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0893\n",
            "Epoch 63/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0893\n",
            "Epoch 64/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0893\n",
            "Epoch 65/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0893\n",
            "Epoch 66/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0893\n",
            "Epoch 67/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0893\n",
            "Epoch 68/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0893\n",
            "Epoch 69/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0893\n",
            "Epoch 70/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0893\n",
            "Epoch 71/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0893\n",
            "Epoch 72/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0893\n",
            "Epoch 73/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0893\n",
            "Epoch 74/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0893\n",
            "Epoch 75/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0893\n",
            "Epoch 76/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0893\n",
            "Epoch 77/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0893\n",
            "Epoch 78/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0893\n",
            "Epoch 79/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0893\n",
            "Epoch 80/100\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0893\n",
            "Epoch 81/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0893\n",
            "Epoch 82/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0893\n",
            "Epoch 83/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0893\n",
            "Epoch 84/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0893\n",
            "Epoch 85/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0893\n",
            "Epoch 86/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0893\n",
            "Epoch 87/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0893\n",
            "Epoch 88/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0893\n",
            "Epoch 89/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0893\n",
            "Epoch 90/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0893\n",
            "Epoch 91/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0893\n",
            "Epoch 92/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0893\n",
            "Epoch 93/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0893\n",
            "Epoch 94/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0893\n",
            "Epoch 95/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0893\n",
            "Epoch 96/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0893\n",
            "Epoch 97/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0893\n",
            "Epoch 98/100\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0893\n",
            "Epoch 99/100\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0893\n",
            "Epoch 100/100\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0893\n",
            "2/2 [==============================] - 0s 5ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7af97d3f9b40>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nXgV1gRR_TuE"
      },
      "source": [
        "We get a pretty nice, expected linear fit (orange +) through the center of the simulated data (blue dots).\n",
        "\n",
        "Incidentally, if you'd like to see the 'best fit' values for the slope and bias of your liner model, you can:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7D61H2e2ApPr",
        "outputId": "06bb7769-2cd4-4c11-ec70-226fdfb04d8f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(model.trainable_variables)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[<tf.Variable 'dense_130/kernel:0' shape=(1, 1) dtype=float32, numpy=array([[0.49912837]], dtype=float32)>, <tf.Variable 'dense_130/bias:0' shape=(1,) dtype=float32, numpy=array([0.01873101], dtype=float32)>]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1u3swcvNApft"
      },
      "source": [
        "This will print the 'raw' tensorflow Variables associated with your neural network. For this 'small' network, there are only 2 trainable variables:\n",
        "\n",
        "* the slope - called the \"kernel\" of the Dense neuron\n",
        "* the y-intercept - called the \"bias\" of the neuron\n",
        "\n",
        "If you look at the printed output, you should see a part that reads\n",
        "\n",
        "    'dense_XXX/kernel:0'\n",
        "\n",
        "where \"XXX\" is an auto-generated number that tensorflow assigns to 'name' the dense layer of your network. After that, you see the specification of the \"kernel\" (ie, slope) variable:\n",
        "\n",
        "    shape=(1, 1) dtype=float32, numpy=array([[0.49990593]], dtype=float32)\n",
        "\n",
        "In my case, the *value* of the best-fit slope was 0.49990593; this is pretty close to 0.5.\n",
        "\n",
        "Similarly, we can find the 'best fit' value for the bias variable by looking for\n",
        "\n",
        "    'dense_XXX/bias:0'\n",
        "\n",
        "and reading its value:\n",
        "\n",
        "    shape=(1,) dtype=float32, numpy=array([0.01880047], dtype=float32)\n",
        "\n",
        "In my case, the 'best fit' y-intercept value was 0.01880047; this is pretty close to 0.0.\n",
        "\n",
        "The\n",
        "\n",
        "    print(model.trainable_variables)\n",
        "\n",
        "statement will print the current values of *all* the trainable parameters in your model. For simple models like this one, we can manually read through the output and interpret the 'meaning' of the values, but for very large networks, printing all the Variables to the screen is unlikely to be very helpful!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ORr_MyXHCoqD"
      },
      "source": [
        "## fitting a nonlinear model to linear data\n",
        "\n",
        "Okay, but we've fit linear models, before. Let's fit a *nonlinear* model to these data, and see how 'good' it is.\n",
        "\n",
        "The following code cell is an end-to-end example, including data simulation, model fitting and plotting the model fit.\n",
        "\n",
        "The only thing missing is the model!\n",
        "\n",
        "In this case, we simulate a small sample of data from a linear model, and we fit a linear model to the data, for comparison.\n",
        "\n",
        "Your job is to build a *nonlinear* neural network model, which should be implemented between the\n",
        "\n",
        "    ## -- BEG BUILD MODEL\n",
        "\n",
        "and\n",
        "\n",
        "    ## -- END BUILD MODEL\n",
        "\n",
        "comments in the code cell. Replace the \"FIXME\" text with your model implementation. Notice that an \"empty\" Sequential model has already been created; you just need to add layers to the empty model, to build your nonlinear neural network.\n",
        "\n",
        "Before you take the quiz, you should *not* change *anything* in the code cell, except for your model implementation. *After* you've completed the quiz, feel free to play around with different model implementations, if you'd like. And remember that you can always grab a 'fresh' version of this notebook from the course link, if you need to.\n",
        "\n",
        "Build your nonlinear model according to the following specification:\n",
        "\n",
        "* Your model should have 4 hidden layers (ie, the network's total depth should be 6).\n",
        "* Use Dense layers for *all* layers in your network.\n",
        "* Use ReLU activations on *all* layers of your network *except* the output layer, which should have *linear* activation.\n",
        "* The width of *all* layers in your model *except* the output layer should be 64.\n",
        "\n",
        "That's it. Please implement your model and run the code cell to confirm it works and check your model's fit."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VEozgEuFDPYp",
        "outputId": "a8afb33b-d27c-49ff-d444-74a26d1aea1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import sklearn.datasets\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "\n",
        "# simulate linear data\n",
        "x,y = sklearn.datasets.make_regression(n_samples=50,\n",
        "                                       n_features=1,\n",
        "                                       bias=0.0,\n",
        "                                       noise=30.0,\n",
        "                                       random_state=602951)\n",
        "y = y / 100.0\n",
        "data = tf.data.Dataset.from_tensor_slices((x,y)).batch(10)\n",
        "\n",
        "# fit linear model, so we can compare later\n",
        "lm = tf.keras.Sequential()\n",
        "lm.add(tf.keras.layers.Dense(units=1, input_shape=[1]))\n",
        "lm.compile(optimizer=tf.keras.optimizers.SGD(),\n",
        "              loss=tf.keras.losses.MeanSquaredError())\n",
        "lm.fit(data, epochs=100, verbose=0)\n",
        "lm_yhat = lm.predict(x)\n",
        "\n",
        "# build and fit nonlinear model\n",
        "model = tf.keras.Sequential()\n",
        "## -- BEG BUILD MODEL\n",
        "model.add(tf.keras.layers.Dense(units=64, activation=tf.keras.activations.relu, input_shape=[1]))\n",
        "model.add(tf.keras.layers.Dense(units=64, activation=tf.keras.activations.relu))\n",
        "model.add(tf.keras.layers.Dense(units=64, activation=tf.keras.activations.relu))\n",
        "model.add(tf.keras.layers.Dense(units=64, activation=tf.keras.activations.relu))\n",
        "model.add(tf.keras.layers.Dense(units=64, activation=tf.keras.activations.relu))\n",
        "model.add(tf.keras.layers.Dense(units=1))\n",
        "\n",
        "## -- END BUILD MODEL\n",
        "model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.1),\n",
        "              loss=tf.keras.losses.MeanSquaredError())\n",
        "model.summary()\n",
        "\n",
        "model.fit(data, epochs=500)\n",
        "\n",
        "y_hat = model.predict(x)\n",
        "\n",
        "# plot results\n",
        "plt.scatter(x,y, marker='o')\n",
        "plt.scatter(x,lm_yhat, marker='+')\n",
        "plt.scatter(x,y_hat, marker='s')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 5ms/step\n",
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_140 (Dense)           (None, 64)                128       \n",
            "                                                                 \n",
            " dense_141 (Dense)           (None, 64)                4160      \n",
            "                                                                 \n",
            " dense_142 (Dense)           (None, 64)                4160      \n",
            "                                                                 \n",
            " dense_143 (Dense)           (None, 64)                4160      \n",
            "                                                                 \n",
            " dense_144 (Dense)           (None, 64)                4160      \n",
            "                                                                 \n",
            " dense_145 (Dense)           (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 16,833\n",
            "Trainable params: 16,833\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/500\n",
            "5/5 [==============================] - 1s 4ms/step - loss: 0.2891\n",
            "Epoch 2/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.1831\n",
            "Epoch 3/500\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.1300\n",
            "Epoch 4/500\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.1128\n",
            "Epoch 5/500\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.1056\n",
            "Epoch 6/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.1017\n",
            "Epoch 7/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0974\n",
            "Epoch 8/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0965\n",
            "Epoch 9/500\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.0962\n",
            "Epoch 10/500\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0979\n",
            "Epoch 11/500\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0993\n",
            "Epoch 12/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0993\n",
            "Epoch 13/500\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0985\n",
            "Epoch 14/500\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0974\n",
            "Epoch 15/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0973\n",
            "Epoch 16/500\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0978\n",
            "Epoch 17/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0972\n",
            "Epoch 18/500\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0959\n",
            "Epoch 19/500\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0959\n",
            "Epoch 20/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0946\n",
            "Epoch 21/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0948\n",
            "Epoch 22/500\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0942\n",
            "Epoch 23/500\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0940\n",
            "Epoch 24/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0929\n",
            "Epoch 25/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0936\n",
            "Epoch 26/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0931\n",
            "Epoch 27/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0925\n",
            "Epoch 28/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0919\n",
            "Epoch 29/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0926\n",
            "Epoch 30/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0918\n",
            "Epoch 31/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0918\n",
            "Epoch 32/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0915\n",
            "Epoch 33/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0911\n",
            "Epoch 34/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0911\n",
            "Epoch 35/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0912\n",
            "Epoch 36/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0905\n",
            "Epoch 37/500\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0907\n",
            "Epoch 38/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0908\n",
            "Epoch 39/500\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0907\n",
            "Epoch 40/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0903\n",
            "Epoch 41/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0902\n",
            "Epoch 42/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0906\n",
            "Epoch 43/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0899\n",
            "Epoch 44/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0898\n",
            "Epoch 45/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0897\n",
            "Epoch 46/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0899\n",
            "Epoch 47/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0897\n",
            "Epoch 48/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0897\n",
            "Epoch 49/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0897\n",
            "Epoch 50/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0900\n",
            "Epoch 51/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0896\n",
            "Epoch 52/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0894\n",
            "Epoch 53/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0897\n",
            "Epoch 54/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0891\n",
            "Epoch 55/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0893\n",
            "Epoch 56/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0895\n",
            "Epoch 57/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0891\n",
            "Epoch 58/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0897\n",
            "Epoch 59/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0895\n",
            "Epoch 60/500\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0893\n",
            "Epoch 61/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0895\n",
            "Epoch 62/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0893\n",
            "Epoch 63/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0891\n",
            "Epoch 64/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0894\n",
            "Epoch 65/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0890\n",
            "Epoch 66/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0893\n",
            "Epoch 67/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0891\n",
            "Epoch 68/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0891\n",
            "Epoch 69/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0894\n",
            "Epoch 70/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0886\n",
            "Epoch 71/500\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0893\n",
            "Epoch 72/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0886\n",
            "Epoch 73/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0892\n",
            "Epoch 74/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0887\n",
            "Epoch 75/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0888\n",
            "Epoch 76/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0888\n",
            "Epoch 77/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0890\n",
            "Epoch 78/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0885\n",
            "Epoch 79/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0885\n",
            "Epoch 80/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0882\n",
            "Epoch 81/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0883\n",
            "Epoch 82/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0885\n",
            "Epoch 83/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0883\n",
            "Epoch 84/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0884\n",
            "Epoch 85/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0882\n",
            "Epoch 86/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0880\n",
            "Epoch 87/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0885\n",
            "Epoch 88/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0881\n",
            "Epoch 89/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0881\n",
            "Epoch 90/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0878\n",
            "Epoch 91/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0879\n",
            "Epoch 92/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0879\n",
            "Epoch 93/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0882\n",
            "Epoch 94/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0877\n",
            "Epoch 95/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0879\n",
            "Epoch 96/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0878\n",
            "Epoch 97/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0879\n",
            "Epoch 98/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0875\n",
            "Epoch 99/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0878\n",
            "Epoch 100/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0877\n",
            "Epoch 101/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0874\n",
            "Epoch 102/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0877\n",
            "Epoch 103/500\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0874\n",
            "Epoch 104/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0878\n",
            "Epoch 105/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0874\n",
            "Epoch 106/500\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0877\n",
            "Epoch 107/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0872\n",
            "Epoch 108/500\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0878\n",
            "Epoch 109/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0871\n",
            "Epoch 110/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0877\n",
            "Epoch 111/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0872\n",
            "Epoch 112/500\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0872\n",
            "Epoch 113/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0871\n",
            "Epoch 114/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0873\n",
            "Epoch 115/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0872\n",
            "Epoch 116/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0873\n",
            "Epoch 117/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0869\n",
            "Epoch 118/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0873\n",
            "Epoch 119/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0869\n",
            "Epoch 120/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0869\n",
            "Epoch 121/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0867\n",
            "Epoch 122/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0866\n",
            "Epoch 123/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0869\n",
            "Epoch 124/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0867\n",
            "Epoch 125/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0865\n",
            "Epoch 126/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0867\n",
            "Epoch 127/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0866\n",
            "Epoch 128/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0862\n",
            "Epoch 129/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0869\n",
            "Epoch 130/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0862\n",
            "Epoch 131/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0866\n",
            "Epoch 132/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0861\n",
            "Epoch 133/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0867\n",
            "Epoch 134/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0859\n",
            "Epoch 135/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0866\n",
            "Epoch 136/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0862\n",
            "Epoch 137/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0864\n",
            "Epoch 138/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0858\n",
            "Epoch 139/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0865\n",
            "Epoch 140/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0860\n",
            "Epoch 141/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0860\n",
            "Epoch 142/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0862\n",
            "Epoch 143/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0858\n",
            "Epoch 144/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0860\n",
            "Epoch 145/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0858\n",
            "Epoch 146/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0862\n",
            "Epoch 147/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0857\n",
            "Epoch 148/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0862\n",
            "Epoch 149/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0857\n",
            "Epoch 150/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0861\n",
            "Epoch 151/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0859\n",
            "Epoch 152/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0856\n",
            "Epoch 153/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0858\n",
            "Epoch 154/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0855\n",
            "Epoch 155/500\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0856\n",
            "Epoch 156/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0859\n",
            "Epoch 157/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0854\n",
            "Epoch 158/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0854\n",
            "Epoch 159/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0860\n",
            "Epoch 160/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0853\n",
            "Epoch 161/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0860\n",
            "Epoch 162/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0854\n",
            "Epoch 163/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0858\n",
            "Epoch 164/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0851\n",
            "Epoch 165/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0854\n",
            "Epoch 166/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0854\n",
            "Epoch 167/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0856\n",
            "Epoch 168/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0853\n",
            "Epoch 169/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0856\n",
            "Epoch 170/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0854\n",
            "Epoch 171/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0855\n",
            "Epoch 172/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0849\n",
            "Epoch 173/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0856\n",
            "Epoch 174/500\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0851\n",
            "Epoch 175/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0855\n",
            "Epoch 176/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0851\n",
            "Epoch 177/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0855\n",
            "Epoch 178/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0851\n",
            "Epoch 179/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0855\n",
            "Epoch 180/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0847\n",
            "Epoch 181/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0854\n",
            "Epoch 182/500\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0849\n",
            "Epoch 183/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0851\n",
            "Epoch 184/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0851\n",
            "Epoch 185/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0850\n",
            "Epoch 186/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0850\n",
            "Epoch 187/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0847\n",
            "Epoch 188/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0851\n",
            "Epoch 189/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0849\n",
            "Epoch 190/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0850\n",
            "Epoch 191/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0848\n",
            "Epoch 192/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0848\n",
            "Epoch 193/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0848\n",
            "Epoch 194/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0849\n",
            "Epoch 195/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0849\n",
            "Epoch 196/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0847\n",
            "Epoch 197/500\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0845\n",
            "Epoch 198/500\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0850\n",
            "Epoch 199/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0846\n",
            "Epoch 200/500\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0847\n",
            "Epoch 201/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0849\n",
            "Epoch 202/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0844\n",
            "Epoch 203/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0850\n",
            "Epoch 204/500\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0847\n",
            "Epoch 205/500\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0848\n",
            "Epoch 206/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0846\n",
            "Epoch 207/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0848\n",
            "Epoch 208/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0842\n",
            "Epoch 209/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0849\n",
            "Epoch 210/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0847\n",
            "Epoch 211/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0845\n",
            "Epoch 212/500\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0845\n",
            "Epoch 213/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0842\n",
            "Epoch 214/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0849\n",
            "Epoch 215/500\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0843\n",
            "Epoch 216/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0841\n",
            "Epoch 217/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0842\n",
            "Epoch 218/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0843\n",
            "Epoch 219/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0843\n",
            "Epoch 220/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0841\n",
            "Epoch 221/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0848\n",
            "Epoch 222/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0842\n",
            "Epoch 223/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0842\n",
            "Epoch 224/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0842\n",
            "Epoch 225/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0842\n",
            "Epoch 226/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0845\n",
            "Epoch 227/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0841\n",
            "Epoch 228/500\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0840\n",
            "Epoch 229/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0840\n",
            "Epoch 230/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0840\n",
            "Epoch 231/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0840\n",
            "Epoch 232/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0840\n",
            "Epoch 233/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0838\n",
            "Epoch 234/500\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0838\n",
            "Epoch 235/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0836\n",
            "Epoch 236/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0841\n",
            "Epoch 237/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0836\n",
            "Epoch 238/500\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0840\n",
            "Epoch 239/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0835\n",
            "Epoch 240/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0838\n",
            "Epoch 241/500\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0837\n",
            "Epoch 242/500\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0842\n",
            "Epoch 243/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0836\n",
            "Epoch 244/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0837\n",
            "Epoch 245/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0836\n",
            "Epoch 246/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0838\n",
            "Epoch 247/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0835\n",
            "Epoch 248/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0837\n",
            "Epoch 249/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0836\n",
            "Epoch 250/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0835\n",
            "Epoch 251/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0833\n",
            "Epoch 252/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0836\n",
            "Epoch 253/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0832\n",
            "Epoch 254/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0835\n",
            "Epoch 255/500\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0831\n",
            "Epoch 256/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0835\n",
            "Epoch 257/500\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0830\n",
            "Epoch 258/500\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0838\n",
            "Epoch 259/500\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0832\n",
            "Epoch 260/500\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0833\n",
            "Epoch 261/500\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0831\n",
            "Epoch 262/500\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0835\n",
            "Epoch 263/500\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0833\n",
            "Epoch 264/500\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0832\n",
            "Epoch 265/500\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0829\n",
            "Epoch 266/500\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0831\n",
            "Epoch 267/500\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.0830\n",
            "Epoch 268/500\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0828\n",
            "Epoch 269/500\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0831\n",
            "Epoch 270/500\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0825\n",
            "Epoch 271/500\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.0831\n",
            "Epoch 272/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0832\n",
            "Epoch 273/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0830\n",
            "Epoch 274/500\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0829\n",
            "Epoch 275/500\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.0828\n",
            "Epoch 276/500\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.0831\n",
            "Epoch 277/500\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0827\n",
            "Epoch 278/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0828\n",
            "Epoch 279/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0828\n",
            "Epoch 280/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0829\n",
            "Epoch 281/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0826\n",
            "Epoch 282/500\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0826\n",
            "Epoch 283/500\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0826\n",
            "Epoch 284/500\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0827\n",
            "Epoch 285/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0824\n",
            "Epoch 286/500\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0827\n",
            "Epoch 287/500\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0827\n",
            "Epoch 288/500\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0822\n",
            "Epoch 289/500\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0827\n",
            "Epoch 290/500\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0826\n",
            "Epoch 291/500\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.0823\n",
            "Epoch 292/500\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0825\n",
            "Epoch 293/500\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.0825\n",
            "Epoch 294/500\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0822\n",
            "Epoch 295/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0826\n",
            "Epoch 296/500\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.0820\n",
            "Epoch 297/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0824\n",
            "Epoch 298/500\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.0825\n",
            "Epoch 299/500\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.0824\n",
            "Epoch 300/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0822\n",
            "Epoch 301/500\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0824\n",
            "Epoch 302/500\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0822\n",
            "Epoch 303/500\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0823\n",
            "Epoch 304/500\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.0824\n",
            "Epoch 305/500\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0822\n",
            "Epoch 306/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0822\n",
            "Epoch 307/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0823\n",
            "Epoch 308/500\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0822\n",
            "Epoch 309/500\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0823\n",
            "Epoch 310/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0820\n",
            "Epoch 311/500\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0821\n",
            "Epoch 312/500\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0822\n",
            "Epoch 313/500\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0821\n",
            "Epoch 314/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0822\n",
            "Epoch 315/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0822\n",
            "Epoch 316/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0821\n",
            "Epoch 317/500\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0822\n",
            "Epoch 318/500\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.0819\n",
            "Epoch 319/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0820\n",
            "Epoch 320/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0823\n",
            "Epoch 321/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0816\n",
            "Epoch 322/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0821\n",
            "Epoch 323/500\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0817\n",
            "Epoch 324/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0818\n",
            "Epoch 325/500\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0822\n",
            "Epoch 326/500\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0820\n",
            "Epoch 327/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0818\n",
            "Epoch 328/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0822\n",
            "Epoch 329/500\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0821\n",
            "Epoch 330/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0817\n",
            "Epoch 331/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0818\n",
            "Epoch 332/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0816\n",
            "Epoch 333/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0821\n",
            "Epoch 334/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0816\n",
            "Epoch 335/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0818\n",
            "Epoch 336/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0817\n",
            "Epoch 337/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0817\n",
            "Epoch 338/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0818\n",
            "Epoch 339/500\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0818\n",
            "Epoch 340/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0817\n",
            "Epoch 341/500\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0816\n",
            "Epoch 342/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0816\n",
            "Epoch 343/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0815\n",
            "Epoch 344/500\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0819\n",
            "Epoch 345/500\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0816\n",
            "Epoch 346/500\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0814\n",
            "Epoch 347/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0817\n",
            "Epoch 348/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0815\n",
            "Epoch 349/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0816\n",
            "Epoch 350/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0815\n",
            "Epoch 351/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0813\n",
            "Epoch 352/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0816\n",
            "Epoch 353/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0814\n",
            "Epoch 354/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0814\n",
            "Epoch 355/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0814\n",
            "Epoch 356/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0815\n",
            "Epoch 357/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0817\n",
            "Epoch 358/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0813\n",
            "Epoch 359/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0814\n",
            "Epoch 360/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0815\n",
            "Epoch 361/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0814\n",
            "Epoch 362/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0813\n",
            "Epoch 363/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0816\n",
            "Epoch 364/500\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0813\n",
            "Epoch 365/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0818\n",
            "Epoch 366/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0815\n",
            "Epoch 367/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0812\n",
            "Epoch 368/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0817\n",
            "Epoch 369/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0814\n",
            "Epoch 370/500\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0815\n",
            "Epoch 371/500\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0816\n",
            "Epoch 372/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0814\n",
            "Epoch 373/500\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0811\n",
            "Epoch 374/500\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0816\n",
            "Epoch 375/500\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0811\n",
            "Epoch 376/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0815\n",
            "Epoch 377/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0816\n",
            "Epoch 378/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0810\n",
            "Epoch 379/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0814\n",
            "Epoch 380/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0814\n",
            "Epoch 381/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0811\n",
            "Epoch 382/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0811\n",
            "Epoch 383/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0813\n",
            "Epoch 384/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0813\n",
            "Epoch 385/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0814\n",
            "Epoch 386/500\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0813\n",
            "Epoch 387/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0813\n",
            "Epoch 388/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0814\n",
            "Epoch 389/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0811\n",
            "Epoch 390/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0815\n",
            "Epoch 391/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0808\n",
            "Epoch 392/500\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0814\n",
            "Epoch 393/500\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0810\n",
            "Epoch 394/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0812\n",
            "Epoch 395/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0810\n",
            "Epoch 396/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0811\n",
            "Epoch 397/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0808\n",
            "Epoch 398/500\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0813\n",
            "Epoch 399/500\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0808\n",
            "Epoch 400/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0812\n",
            "Epoch 401/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0811\n",
            "Epoch 402/500\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0810\n",
            "Epoch 403/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0810\n",
            "Epoch 404/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0811\n",
            "Epoch 405/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0808\n",
            "Epoch 406/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0813\n",
            "Epoch 407/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0810\n",
            "Epoch 408/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0810\n",
            "Epoch 409/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0812\n",
            "Epoch 410/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0807\n",
            "Epoch 411/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0809\n",
            "Epoch 412/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0809\n",
            "Epoch 413/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0808\n",
            "Epoch 414/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0810\n",
            "Epoch 415/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0809\n",
            "Epoch 416/500\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0811\n",
            "Epoch 417/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0806\n",
            "Epoch 418/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0812\n",
            "Epoch 419/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0808\n",
            "Epoch 420/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0808\n",
            "Epoch 421/500\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0810\n",
            "Epoch 422/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0806\n",
            "Epoch 423/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0808\n",
            "Epoch 424/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0808\n",
            "Epoch 425/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0810\n",
            "Epoch 426/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0806\n",
            "Epoch 427/500\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0807\n",
            "Epoch 428/500\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0806\n",
            "Epoch 429/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0809\n",
            "Epoch 430/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0809\n",
            "Epoch 431/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0807\n",
            "Epoch 432/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0806\n",
            "Epoch 433/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0807\n",
            "Epoch 434/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0807\n",
            "Epoch 435/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0806\n",
            "Epoch 436/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0807\n",
            "Epoch 437/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0804\n",
            "Epoch 438/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0806\n",
            "Epoch 439/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0807\n",
            "Epoch 440/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0804\n",
            "Epoch 441/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0807\n",
            "Epoch 442/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0804\n",
            "Epoch 443/500\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0805\n",
            "Epoch 444/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0806\n",
            "Epoch 445/500\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0805\n",
            "Epoch 446/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0804\n",
            "Epoch 447/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0804\n",
            "Epoch 448/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0806\n",
            "Epoch 449/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0805\n",
            "Epoch 450/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0804\n",
            "Epoch 451/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0807\n",
            "Epoch 452/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0803\n",
            "Epoch 453/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0805\n",
            "Epoch 454/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0807\n",
            "Epoch 455/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0800\n",
            "Epoch 456/500\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0804\n",
            "Epoch 457/500\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0802\n",
            "Epoch 458/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0807\n",
            "Epoch 459/500\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0801\n",
            "Epoch 460/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0804\n",
            "Epoch 461/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0804\n",
            "Epoch 462/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0800\n",
            "Epoch 463/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0805\n",
            "Epoch 464/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0800\n",
            "Epoch 465/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0804\n",
            "Epoch 466/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0800\n",
            "Epoch 467/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0800\n",
            "Epoch 468/500\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0803\n",
            "Epoch 469/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0803\n",
            "Epoch 470/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0804\n",
            "Epoch 471/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0798\n",
            "Epoch 472/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0802\n",
            "Epoch 473/500\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0801\n",
            "Epoch 474/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0805\n",
            "Epoch 475/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0797\n",
            "Epoch 476/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0803\n",
            "Epoch 477/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0802\n",
            "Epoch 478/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0800\n",
            "Epoch 479/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0799\n",
            "Epoch 480/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0802\n",
            "Epoch 481/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0800\n",
            "Epoch 482/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0796\n",
            "Epoch 483/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0803\n",
            "Epoch 484/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0801\n",
            "Epoch 485/500\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0800\n",
            "Epoch 486/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0803\n",
            "Epoch 487/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0796\n",
            "Epoch 488/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0798\n",
            "Epoch 489/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0800\n",
            "Epoch 490/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0798\n",
            "Epoch 491/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0801\n",
            "Epoch 492/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0799\n",
            "Epoch 493/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0801\n",
            "Epoch 494/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0796\n",
            "Epoch 495/500\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0799\n",
            "Epoch 496/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0799\n",
            "Epoch 497/500\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0799\n",
            "Epoch 498/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0799\n",
            "Epoch 499/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0800\n",
            "Epoch 500/500\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0797\n",
            "2/2 [==============================] - 0s 6ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7af97a161d80>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rYWmSFMUZO73"
      },
      "source": [
        "In the plot, the blue circles indicate the 'true' simulated data. The orange + indicates the best-fit *linear* model, and the green squares indicate the fit to the training data for your *nonlinear* neural network.\n",
        "\n",
        "Do you think the nonlinear model is a 'better' fit?"
      ]
    }
  ]
}